{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eouMoNrQ4F0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eouMoNrQ4F0",
    "outputId": "e8b864a4-3b27-42e4-81f4-1cc1e9e7d538"
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bb697a",
   "metadata": {
    "id": "a2bb697a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "#from utils import *\n",
    "\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import torch.nn.utils.prune as prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5feec43",
   "metadata": {
    "id": "a5feec43"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5e686f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f5e686f",
    "outputId": "0353a5b7-dbe7-4ca5-baf3-83b953ed13b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d79d89",
   "metadata": {
    "id": "e6d79d89"
   },
   "outputs": [],
   "source": [
    "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c734c7d0",
   "metadata": {
    "id": "c734c7d0"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = GCN(dataset.num_features, dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1712f23",
   "metadata": {
    "id": "d1712f23"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "\n",
    "    model.eval()\n",
    "    logits, accs = model(dataset[0]), []\n",
    "    for _, mask in dataset[0]( 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(dataset[0].y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f5f37",
   "metadata": {
    "id": "342f5f37"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model(dataset[0]), dataset[0].y).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    val_acc, test_acc = test()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f35a3",
   "metadata": {
    "id": "b07f35a3"
   },
   "outputs": [],
   "source": [
    " val_acc, test_acc = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2040c",
   "metadata": {
    "id": "a6d2040c",
    "outputId": "bb95b946-fe52-4f5a-f7d8-c6018c6cc679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428 0.928 0.925\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3fc3d",
   "metadata": {
    "id": "b8e3fc3d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015dd5fd",
   "metadata": {
    "id": "015dd5fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162c7c3",
   "metadata": {
    "id": "b162c7c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d02beede",
   "metadata": {
    "id": "d02beede"
   },
   "source": [
    "Epoch: 059, Train: 0.9848, Test: 0.9020\n",
    "Epoch: 104, Train: 0.9830, Test: 0.9100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303d796",
   "metadata": {
    "id": "c303d796"
   },
   "source": [
    "##  Measurement of avarage of accuracy, and time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9961ba",
   "metadata": {
    "id": "df9961ba"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics as stat\n",
    "\n",
    "\n",
    "Eva_final=dict()\n",
    "\n",
    "\n",
    "Base_model_Acc=[]\n",
    "T_base_model=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dfff32b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dfff32b",
    "outputId": "d9cda1ec-57cd-4579-e032-9bca3a215527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Val: 0.9080, Test: 0.9120\n",
      "Epoch: 040, Val: 0.9400, Test: 0.9290\n",
      "Epoch: 060, Val: 0.9460, Test: 0.9380\n",
      "Epoch: 080, Val: 0.9500, Test: 0.9460\n",
      "Train Accuracy: 0.958, Test Accuracy: 0.952, Time inference:0.00552821159362793\n",
      "Epoch: 020, Val: 0.9040, Test: 0.9070\n",
      "Epoch: 040, Val: 0.9360, Test: 0.9280\n",
      "Epoch: 060, Val: 0.9400, Test: 0.9350\n",
      "Epoch: 080, Val: 0.9500, Test: 0.9530\n",
      "Train Accuracy: 0.954, Test Accuracy: 0.952, Time inference:0.006078481674194336\n",
      "Epoch: 020, Val: 0.9080, Test: 0.8980\n",
      "Epoch: 040, Val: 0.9260, Test: 0.9250\n",
      "Epoch: 060, Val: 0.9380, Test: 0.9310\n",
      "Epoch: 080, Val: 0.9600, Test: 0.9450\n",
      "Train Accuracy: 0.956, Test Accuracy: 0.943, Time inference:0.008569717407226562\n",
      "Epoch: 020, Val: 0.8980, Test: 0.8950\n",
      "Epoch: 040, Val: 0.9320, Test: 0.9230\n",
      "Epoch: 060, Val: 0.9420, Test: 0.9360\n",
      "Epoch: 080, Val: 0.9520, Test: 0.9450\n",
      "Train Accuracy: 0.96, Test Accuracy: 0.951, Time inference:0.005553722381591797\n",
      "Epoch: 020, Val: 0.9020, Test: 0.8860\n",
      "Epoch: 040, Val: 0.9340, Test: 0.9270\n",
      "Epoch: 060, Val: 0.9500, Test: 0.9410\n",
      "Epoch: 080, Val: 0.9520, Test: 0.9440\n",
      "Train Accuracy: 0.958, Test Accuracy: 0.952, Time inference:0.005684375762939453\n",
      "Epoch: 020, Val: 0.9060, Test: 0.8940\n",
      "Epoch: 040, Val: 0.9400, Test: 0.9290\n",
      "Epoch: 060, Val: 0.9460, Test: 0.9440\n",
      "Epoch: 080, Val: 0.9500, Test: 0.9500\n",
      "Train Accuracy: 0.954, Test Accuracy: 0.953, Time inference:0.006142139434814453\n",
      "Epoch: 020, Val: 0.8920, Test: 0.8920\n",
      "Epoch: 040, Val: 0.9280, Test: 0.9230\n",
      "Epoch: 060, Val: 0.9420, Test: 0.9340\n",
      "Epoch: 080, Val: 0.9560, Test: 0.9430\n",
      "Train Accuracy: 0.952, Test Accuracy: 0.953, Time inference:0.005501747131347656\n",
      "Epoch: 020, Val: 0.9000, Test: 0.8890\n",
      "Epoch: 040, Val: 0.9360, Test: 0.9210\n",
      "Epoch: 060, Val: 0.9400, Test: 0.9380\n",
      "Epoch: 080, Val: 0.9460, Test: 0.9420\n",
      "Train Accuracy: 0.952, Test Accuracy: 0.947, Time inference:0.00612950325012207\n",
      "Epoch: 020, Val: 0.9060, Test: 0.9050\n",
      "Epoch: 040, Val: 0.9400, Test: 0.9210\n",
      "Epoch: 060, Val: 0.9440, Test: 0.9380\n",
      "Epoch: 080, Val: 0.9480, Test: 0.9460\n",
      "Train Accuracy: 0.946, Test Accuracy: 0.953, Time inference:0.005793571472167969\n",
      "Epoch: 020, Val: 0.8980, Test: 0.8940\n",
      "Epoch: 040, Val: 0.9260, Test: 0.9230\n",
      "Epoch: 060, Val: 0.9420, Test: 0.9420\n",
      "Epoch: 080, Val: 0.9460, Test: 0.9480\n",
      "Train Accuracy: 0.958, Test Accuracy: 0.951, Time inference:0.008510351181030273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "\n",
    "\n",
    "        model = GCN(dataset.num_features, dataset.num_classes)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "        for epoch in range(1, 100):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            F.nll_loss(model(dataset[0]), dataset[0].y).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            val_acc, test_acc = test()\n",
    "            if epoch % 20 == 0:\n",
    "                    print(f'Epoch: {epoch:03d}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        train_acc, test_acc = test()\n",
    "        end = time.time()\n",
    "        t_inference= end-start\n",
    "\n",
    "        print(f\"Train Accuracy: {train_acc}, Test Accuracy: {test_acc}, Time inference:{t_inference}\")\n",
    "\n",
    "\n",
    "        Base_model_Acc.append(test_acc)\n",
    "        T_base_model.append(t_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "en1LMdioRk96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "en1LMdioRk96",
    "outputId": "ee8c1646-b969-41f7-fd78-602b8fb7905d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_model_Auc in ten time:\n",
      "0.952     |0.952     |0.943     |0.951     |0.952     |0.953     |0.953     |0.947     |0.953          |0.951               \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Time Inference model in ten time:\n",
      "0.00552821159362793|0.006078481674194336|0.008569717407226562|0.005553722381591797|0.005684375762939453|0.006142139434814453|0.005501747131347656|0.00612950325012207|0.005793571472167969|0.008510351181030273\n"
     ]
    }
   ],
   "source": [
    "print(f'Base_model_Acc in ten time:')\n",
    "print (\"{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<15}|{:<20}\"\\\n",
    "    .format(Base_model_Acc[0],Base_model_Acc[1],Base_model_Acc[2],\\\n",
    "        Base_model_Acc[3],Base_model_Acc[4],Base_model_Acc[5],\\\n",
    "        Base_model_Acc[6],Base_model_Acc[7],Base_model_Acc[8],Base_model_Acc[9]))\n",
    "print (\"-\"*110)\n",
    "print(f'Time Inference model in ten time:')\n",
    "#print(T_base_model)\n",
    "print (\"{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<10}|{:<15}|{:<20}\"\\\n",
    "    .format(T_base_model[0],T_base_model[1],T_base_model[2],\\\n",
    "        T_base_model[3],T_base_model[4],T_base_model[5],\\\n",
    "        T_base_model[6],T_base_model[7],T_base_model[8],T_base_model[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dEmcmCS3RxzU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEmcmCS3RxzU",
    "outputId": "9c96d85b-bc36-4927-dd52-a60c5d489124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc: 0.951 ± 0.003\n",
      "Time inference :0.006 ± 0.001\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "\n",
    "base_model_accuracy_mean = stat.mean(Base_model_Acc)\n",
    "base_model_accuracy_std =  stat.stdev(Base_model_Acc)\n",
    "desc_auc = \"{:.3f} ± {:.3f}\".format(base_model_accuracy_mean,base_model_accuracy_std)\n",
    "print(f\"Auc: {desc_auc}\"  )\n",
    "\n",
    "Eva_final.update({'base model accuracy':float(format(base_model_accuracy_mean, '.4f'))})\n",
    "\n",
    "t_base_model_mean =stat.mean(T_base_model)\n",
    "t_base_model_std =stat.stdev(T_base_model)\n",
    "desc_T = \"{:.3f} ± {:.3f}\".format(t_base_model_mean,t_base_model_std)\n",
    "\n",
    "print(f\"Time inference :{desc_T}\")\n",
    "Eva_final.update({'time inference of base model':float(format(t_base_model_mean, '.6f'))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "WzqAe3QySaKd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzqAe3QySaKd",
    "outputId": "95f4818f-f98b-4347-b457-03d590c17c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 738016\n"
     ]
    }
   ],
   "source": [
    "def get_num_parameters(model, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "\n",
    "print(f\"Model Size: {get_model_size(model)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
